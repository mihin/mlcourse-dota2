{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General information\n",
    "\n",
    "This kernel is intented to help mlcourse.ai participants with doing EDA, Feature Engineering and building models.\n",
    "\n",
    "* At first I'll do basic EDA of the data;\n",
    "* After this I'll build a baseline model to see how good model can be on the basic data;\n",
    "* Then I'll create new features based on the main features and train a model again to see whether there is an improvement;\n",
    "* After this I'll try to extract new features from json files and see whether it helps;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import collections\n",
    "import datetime\n",
    "import json\n",
    "import ast\n",
    "import time\n",
    "from scipy import stats\n",
    "import os\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_selection import GenericUnivariateSelect, SelectPercentile, SelectKBest, f_classif, mutual_info_classif, RFE\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold, cross_val_score, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import shap\n",
    "from tqdm import tqdm_notebook\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# import json\n",
    "import altair as alt\n",
    "from  altair.vega import v3\n",
    "from IPython.display import HTML\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import ujson as json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ColumnDataProcessor:\n",
    "\n",
    "    def replaceNaNValues(self, A):\n",
    "        A[np.isnan(A)] = 0\n",
    "        A[np.isinf(A)] = 0\n",
    "        return A\n",
    "\n",
    "    def add_feature_average(self, df, c, r_columns, d_columns):\n",
    "        df['r_total_' + c] = df[r_columns].sum(1)\n",
    "        df['d_total_' + c] = df[d_columns].sum(1)\n",
    "        df['total_' + c + '_ratio'] = df['r_total_' + c] / df['d_total_' + c]\n",
    "        df['total_' + c + '_ratio'] = self.replaceNaNValues(df['total_' + c + '_ratio'])\n",
    "\n",
    "        df['r_std_' + c] = df[r_columns].std(1)\n",
    "        df['d_std_' + c] = df[d_columns].std(1)\n",
    "        df['std_' + c + '_ratio'] = df['r_std_' + c] / df['d_std_' + c]\n",
    "        df['std_' + c + '_ratio'] = self.replaceNaNValues(df['std_' + c + '_ratio'])\n",
    "\n",
    "        df['r_mean_' + c] = df[r_columns].mean(1)\n",
    "        df['d_mean_' + c] = df[d_columns].mean(1)\n",
    "        df['mean_' + c + '_ratio'] = df['r_mean_' + c] / df['d_mean_' + c]\n",
    "        df['mean_' + c + '_ratio'] = self.replaceNaNValues(df['mean_' + c + '_ratio'])\n",
    "\n",
    "        df = df.drop(r_columns, axis=1).reset_index(drop=True)\n",
    "        df = df.drop(d_columns, axis=1).reset_index(drop=True)\n",
    "        df = df.drop(\n",
    "            ['r_total_' + c, 'd_total_' + c, 'r_std_' + c, 'd_std_' + c, 'r_mean_' + c, 'd_mean_' + c],\n",
    "            axis=1).reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def prepare_data(self, train, target, test, features_list):\n",
    "        for c in features_list:\n",
    "            r_columns = [f'r{i}_{c}' for i in range(1, 6)]\n",
    "            d_columns = [f'd{i}_{c}' for i in range(1, 6)]\n",
    "\n",
    "            train = self.add_feature_average(train, c, r_columns, d_columns)\n",
    "            test = self.add_feature_average(test, c, r_columns, d_columns)\n",
    "\n",
    "        r_heroes = [f'r{i}_hero_id' for i in range(1, 6)]\n",
    "        d_heroes = [f'd{i}_hero_id' for i in range(1, 6)]\n",
    "        feat_to_drop = ['game_time', 'game_mode', 'lobby_type', 'objectives_len', 'chat_len'] # + r_heroes + d_heroes\n",
    "        train = train.drop(feat_to_drop, axis=1).reset_index(drop=True)\n",
    "        test = test.drop(feat_to_drop, axis=1).reset_index(drop=True)\n",
    "\n",
    "        if self.to_scale:\n",
    "            features_to_scale = ['total_' + c + '_ratio', 'std_' + c + '_ratio', 'mean_' + c + '_ratio'] + r_heroes + d_heroes\n",
    "            scaler = MinMaxScaler()\n",
    "            train[features_to_scale] = scaler.fit_transform(train[features_to_scale])\n",
    "            test[features_to_scale] = scaler.transform(test[features_to_scale])\n",
    "\n",
    "        return self.prepare_data_simple(train, target, test)\n",
    "\n",
    "    def prepare_data_simple(self, train, targets, test):\n",
    "        X = train.reset_index(drop=True)\n",
    "        y = targets['radiant_win']\n",
    "        X_test = test.reset_index(drop=True)\n",
    "\n",
    "        for col in train.columns:\n",
    "            if train[col].isnull().any():\n",
    "                print(col, train[col].isnull().sum())\n",
    "\n",
    "        for col in test.columns:\n",
    "            if test[col].isnull().any():\n",
    "                print(col, test[col].isnull().sum())\n",
    "\n",
    "        return X, y, X_test\n",
    "\n",
    "\n",
    "class CSVDataPrepare:\n",
    "\n",
    "    def read_data_frame(self):\n",
    "        PATH_TO_DATA = '../input/'\n",
    "\n",
    "        # Train dataset\n",
    "        df_train_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_features.csv'), index_col='match_id_hash')\n",
    "        df_train_targets = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_targets.csv'), index_col='match_id_hash')\n",
    "        # Test dataset\n",
    "        df_test_features = pd.read_csv(os.path.join(PATH_TO_DATA, 'test_features.csv'), index_col='match_id_hash')\n",
    "        # Check if there is missing data\n",
    "        print(\"Original data frame: \")\n",
    "        # print('df_train_features.isnull() {}'.format(df_train_features.isnull().values.any()))\n",
    "        # print('df_test_features.isnull() {}'.format(df_test_features.isnull().values.any()))\n",
    "        print(df_train_features.shape)\n",
    "        return df_train_features, df_train_targets, df_test_features\n",
    "\n",
    "    def prepareDataOld(self, train, target, test):\n",
    "        # Let's combine train and test datasets in one dataset.\n",
    "        # This allows for addding new features for both datasets at the same time.\n",
    "        df_full_features = pd.concat([train, test])\n",
    "\n",
    "        # Index to split the training and test data sets\n",
    "        idx_split = train.shape[0]\n",
    "\n",
    "        # That is,\n",
    "        # df_train_features == df_full_features[:idx_split]\n",
    "        # df_test_features == df_full_features[idx_split:]\n",
    "\n",
    "        df_full_features.drop(['game_time', 'game_mode', 'lobby_type', 'objectives_len', 'chat_len'],\n",
    "                              inplace=True, axis=1)\n",
    "\n",
    "        # Clearly the hero_id is a categorical feature, so let's one-hot encode it. Note that according to wiki there are\n",
    "        # 117 heroes, however in our dataset there are 116 heroes with ids 1, 2, ..., 114, 119, 120.\n",
    "        # You will get the same result for all teams and players, here I use r1.\n",
    "        np.sort(np.unique(df_full_features['r1_hero_id'].values.flatten()))\n",
    "\n",
    "        for t in ['r', 'd']:\n",
    "            for i in range(1, 6):\n",
    "                df_full_features = pd.get_dummies(df_full_features, columns=[f'{t}{i}_hero_id'])\n",
    "        #         df_full_features = pd.concat([df_full_features,\n",
    "        #           pd.get_dummies(df_full_features[f'{t}{i}_hero_id'], prefix=f'{t}{i}_hero_id')], axis=1)\n",
    "\n",
    "        # Finally let's scale the player-features that have relatively large values, such as gold, lh, xp etc.\n",
    "        player_features = set(f[3:] for f in train.columns[5:])\n",
    "        features_to_scale = []\n",
    "        for t in ['r', 'd']:\n",
    "            for i in range(1, 6):\n",
    "                for f in player_features - {'hero_id', 'firstblood_claimed', 'teamfight_participation'}:\n",
    "                    features_to_scale.append(f'{t}{i}_{f}')\n",
    "        df_full_features_scaled = df_full_features.copy()\n",
    "        df_full_features_scaled[features_to_scale] = MinMaxScaler().fit_transform(\n",
    "            df_full_features_scaled[features_to_scale])\n",
    "\n",
    "        df_full_features_scaled.head()\n",
    "        df_full_features_scaled.max().sort_values(ascending=False).head(12)\n",
    "\n",
    "        # Let's construct X and y arrays.\n",
    "        X_train = df_full_features_scaled[:idx_split]\n",
    "        X_test = df_full_features_scaled[idx_split:]\n",
    "        y_train = target['radiant_win'].map({True: 1, False: 0})\n",
    "\n",
    "        print(X_train.head())\n",
    "        print(X_train.describe())\n",
    "\n",
    "        # splitting whole dataset on train and test\n",
    "        # X_train = data.loc[:test_index].drop([\"y\"], axis=1)\n",
    "        # y_train = data.loc[:test_index][\"y\"]\n",
    "        # X_test = data.loc[test_index:].drop([\"y\"], axis=1)\n",
    "        # y_test = data.loc[test_index:][\"y\"]\n",
    "\n",
    "        return X_train, X_test, y_train\n",
    "\n",
    "    def prepareValidationTensors(self, X_train, X_test, y_train, test_size=0.2):\n",
    "        # Perform a train/validation split\n",
    "        X_train_part, X_valid, y_train_part, y_valid = train_test_split(X_train, y_train,\n",
    "                                                                        test_size=test_size,\n",
    "                                                                        random_state=SEED)\n",
    "\n",
    "        # Convert to pytorch tensors\n",
    "        X_train_tensor = torch.from_numpy(X_train_part.values).float()\n",
    "        X_valid_tensor = torch.from_numpy(X_valid.values).float()\n",
    "        y_train_tensor = torch.from_numpy(y_train_part.values).float()\n",
    "        y_valid_tensor = torch.from_numpy(y_valid.values).float()\n",
    "        X_test_tensor = torch.from_numpy(X_test.values).float()\n",
    "\n",
    "        # Create the train and validation dataloaders\n",
    "        train_dataset = data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        valid_dataset = data.TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "\n",
    "        dataloaders = {'train': data.DataLoader(train_dataset, batch_size=1000, shuffle=True, num_workers=2),\n",
    "                       'valid': data.DataLoader(valid_dataset, batch_size=1000, shuffle=False, num_workers=2)}\n",
    "        return dataloaders, X_train_tensor, X_valid_tensor, y_train_tensor, y_valid_tensor, X_test_tensor\n",
    "\n",
    "    # My idea behind this FE is the following: Let's take gold, for example. Gold earned by each player can't give\n",
    "    # us a lot of information. But what is we take total gold by the team? Maybe teams with more gold earned usually\n",
    "    # win. What if we take mean and std of players' gold in a team? Maybe teams where players tend to have similar\n",
    "    # parameters are more likely to win. Let's try creating these features.\n",
    "    FEATURES_LIST = ['kills', 'deaths', 'assists', 'denies', 'gold', 'lh', 'xp', 'health', 'max_health', 'max_mana',\n",
    "                     'level', 'x', 'y', 'stuns', 'creeps_stacked', 'camps_stacked', 'rune_pickups',\n",
    "                     'firstblood_claimed', 'teamfight_participation', 'towers_killed', 'roshans_killed', 'obs_placed',\n",
    "                     'sen_placed']\n",
    "\n",
    "    def prepare_data(self, train, target, test):\n",
    "        engineering = ColumnDataProcessor()\n",
    "        train, target, test = engineering.prepare_data(train, target, test, self.FEATURES_LIST)\n",
    "\n",
    "        return train, target, test\n",
    "\n",
    "\n",
    "class JsonDataPrepare:\n",
    "    MATCH_FEATURES = [\n",
    "        ('game_time', lambda m: m['game_time']),\n",
    "        ('game_mode', lambda m: m['game_mode']),\n",
    "        ('lobby_type', lambda m: m['lobby_type']),\n",
    "        ('objectives_len', lambda m: len(m['objectives'])),\n",
    "        ('chat_len', lambda m: len(m['chat'])),\n",
    "    ]\n",
    "\n",
    "    PLAYER_FIELDS = [\n",
    "        'hero_id',\n",
    "\n",
    "        'kills',\n",
    "        'deaths',\n",
    "        'assists',\n",
    "        'denies',\n",
    "\n",
    "        'gold',\n",
    "        'lh',\n",
    "        'xp',\n",
    "        'health',\n",
    "        'max_health',\n",
    "        'max_mana',\n",
    "        'level',\n",
    "\n",
    "        'x',\n",
    "        'y',\n",
    "\n",
    "        'stuns',\n",
    "        'creeps_stacked',\n",
    "        'camps_stacked',\n",
    "        'rune_pickups',\n",
    "        'firstblood_claimed',\n",
    "        'teamfight_participation',\n",
    "        'towers_killed',\n",
    "        'roshans_killed',\n",
    "        'obs_placed',\n",
    "        'sen_placed',\n",
    "    ]\n",
    "\n",
    "    def extract_features_csv(self, match):\n",
    "        row = [\n",
    "            ('match_id_hash', match['match_id_hash']),\n",
    "        ]\n",
    "\n",
    "        for field, f in self.MATCH_FEATURES:\n",
    "            row.append((field, f(match)))\n",
    "\n",
    "        for slot, player in enumerate(match['players']):\n",
    "            if slot < 5:\n",
    "                player_name = 'r%d' % (slot + 1)\n",
    "            else:\n",
    "                player_name = 'd%d' % (slot - 4)\n",
    "\n",
    "            for field in self.PLAYER_FIELDS:\n",
    "                column_name = '%s_%s' % (player_name, field)\n",
    "                row.append((column_name, player[field]))\n",
    "            row.append((f'{player_name}_ability_level', len(player['ability_upgrades'])))\n",
    "            row.append((f'{player_name}_max_hero_hit', player['max_hero_hit']['value']))\n",
    "            row.append((f'{player_name}_purchase_count', len(player['purchase_log'])))\n",
    "            row.append((f'{player_name}_count_ability_use', sum(player['ability_uses'].values())))\n",
    "            row.append((f'{player_name}_damage_dealt', sum(player['damage'].values())))\n",
    "            row.append((f'{player_name}_damage_received', sum(player['damage_taken'].values())))\n",
    "\n",
    "        return collections.OrderedDict(row)\n",
    "\n",
    "    def extract_targets_csv(self, match, targets):\n",
    "        return collections.OrderedDict([('match_id_hash', match['match_id_hash'])] + [\n",
    "            (field, targets[field])\n",
    "            for field in ['game_time', 'radiant_win', 'duration', 'time_remaining', 'next_roshan_team']\n",
    "        ])\n",
    "\n",
    "    def read_matches(self, matches_file):\n",
    "        MATCHES_COUNT = {\n",
    "            'test_matches.jsonl': 10000,\n",
    "            'train_matches.jsonl': 39675,\n",
    "        }\n",
    "        _, filename = os.path.split(matches_file)\n",
    "        total_matches = MATCHES_COUNT.get(filename)\n",
    "\n",
    "        with open(matches_file) as fin:\n",
    "            for line in tqdm_notebook(fin, total=total_matches):\n",
    "                yield json.loads(line)\n",
    "\n",
    "    def read_data_frame(self):\n",
    "        PATH_TO_DATA = '../input/'\n",
    "        df_new_features = []\n",
    "        df_new_targets = []\n",
    "\n",
    "        for match in self.read_matches(os.path.join(PATH_TO_DATA, 'train_matches.jsonl')):\n",
    "            # match_id_hash = match['match_id_hash']\n",
    "            features = self.extract_features_csv(match)\n",
    "            targets = self.extract_targets_csv(match, match['targets'])\n",
    "\n",
    "            df_new_features.append(features)\n",
    "            df_new_targets.append(targets)\n",
    "\n",
    "        df_new_features = pd.DataFrame.from_records(df_new_features).set_index('match_id_hash')\n",
    "        df_new_targets = pd.DataFrame.from_records(df_new_targets).set_index('match_id_hash')\n",
    "\n",
    "        test_new_features = []\n",
    "        for match in self.read_matches(os.path.join(PATH_TO_DATA, 'test_matches.jsonl')):\n",
    "            # match_id_hash = match['match_id_hash']\n",
    "            features = self.extract_features_csv(match)\n",
    "\n",
    "            test_new_features.append(features)\n",
    "\n",
    "        test_new_features = pd.DataFrame.from_records(test_new_features).set_index('match_id_hash')\n",
    "\n",
    "        print(df_new_features.shape)\n",
    "\n",
    "        return df_new_features, df_new_targets, test_new_features\n",
    "\n",
    "    FEATURES_LIST = ['kills', 'deaths', 'assists', 'denies', 'gold', 'lh', 'xp', 'health', 'max_health', 'max_mana',\n",
    "                     'level', 'x', 'y', 'stuns', 'creeps_stacked', 'camps_stacked', 'rune_pickups',\n",
    "                     'firstblood_claimed', 'teamfight_participation', 'towers_killed', 'roshans_killed', 'obs_placed',\n",
    "                     'sen_placed', 'ability_level', 'max_hero_hit', 'purchase_count', 'count_ability_use',\n",
    "                     'damage_dealt', 'damage_received']\n",
    "\n",
    "    def prepare_data(self, train, target, test):\n",
    "        engineering = ColumnDataProcessor()\n",
    "        train, target, test = engineering.prepare_data(train, target, test, self.FEATURES_LIST)\n",
    "\n",
    "        return train, target, test\n",
    "\n",
    "\n",
    "\n",
    "data_loader_csv = CSVDataPrepare()\n",
    "data_loader_json = JsonDataPrepare()\n",
    "data_loader = data_loader_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b34173535c4d459ff4a278ebb60a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39675), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ebeb1e69c4cd298b3c6475366add9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(39675, 305)\n"
     ]
    }
   ],
   "source": [
    "df_train_features, df_train_targets, df_test_features = data_loader.read_data_frame();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ColumnDataProcessor' object has no attribute 'to_scale'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-492ed0b69577>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-ee81edc5bf0d>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, train, target, test)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mengineering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColumnDataProcessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mengineering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFEATURES_LIST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-ee81edc5bf0d>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, train, target, test, features_list)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat_to_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_scale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mfeatures_to_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'total_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ratio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'std_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ratio'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_ratio'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mr_heroes\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0md_heroes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ColumnDataProcessor' object has no attribute 'to_scale'"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test = data_loader.prepare_data(df_train_features.copy(), df_train_targets.copy(), df_test_features.copy())\n",
    "\n",
    "print(X_train.shape)\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.describe()\n",
    "# X_train = X_train.drop(['r1_kills'], axis=1)\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "folds = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "_kg_hide-input": false
   },
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, params, folds, model_type='lgb', plot_feature_importance=False, averaging='usual', model=None):\n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    for fold_n, (train_index, valid_index) in enumerate(folds.split(X, y)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, X_valid = X.loc[train_index], X.loc[valid_index]\n",
    "        y_train, y_valid = y[train_index], y[valid_index]\n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            train_data = lgb.Dataset(X_train, label=y_train)\n",
    "            valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "            \n",
    "            model = lgb.train(params,\n",
    "                    train_data,\n",
    "                    num_boost_round=20000,\n",
    "                    valid_sets = [train_data, valid_data],\n",
    "                    verbose_eval=1000,\n",
    "                    early_stopping_rounds = 200)\n",
    "            \n",
    "            y_pred_valid = model.predict(X_valid)\n",
    "            y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "            \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X_train.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X_train.columns)\n",
    "\n",
    "            watchlist = [(train_data, 'train'), (valid_data, 'valid_data')]\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X_train.columns), ntree_limit=model.best_ntree_limit)\n",
    "        \n",
    "        if model_type == 'sklearn':\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict_proba(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            # print(f'Fold {fold_n}. AUC: {score:.4f}.')\n",
    "            # print('')\n",
    "            \n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        if model_type == 'glm':\n",
    "            model = sm.GLM(y_train, X_train, family=sm.families.Binomial())\n",
    "            model_results = model.fit()\n",
    "            model_results.predict(X_test)\n",
    "            y_pred_valid = model_results.predict(X_valid).reshape(-1,)\n",
    "            score = roc_auc_score(y_valid, y_pred_valid)\n",
    "            \n",
    "            y_pred = model_results.predict(X_test)\n",
    "            \n",
    "        if model_type == 'cat':\n",
    "            model = CatBoostClassifier(iterations=20000, learning_rate=0.05, loss_function='Logloss',  eval_metric='AUC', **params)\n",
    "            model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=[], use_best_model=True, verbose=False)\n",
    "\n",
    "            y_pred_valid = model.predict_proba(X_valid)[:, 1]\n",
    "            y_pred = model.predict_proba(X_test)[:, 1]\n",
    "            \n",
    "        oof[valid_index] = y_pred_valid.reshape(-1,)\n",
    "        scores.append(roc_auc_score(y_valid, y_pred_valid))\n",
    "\n",
    "        if averaging == 'usual':\n",
    "            prediction += y_pred\n",
    "        elif averaging == 'rank':\n",
    "            prediction += pd.Series(y_pred).rank().values  \n",
    "        \n",
    "        if model_type == 'lgb':\n",
    "            # feature importance\n",
    "            fold_importance = pd.DataFrame()\n",
    "            fold_importance[\"feature\"] = X.columns\n",
    "            fold_importance[\"importance\"] = model.feature_importance()\n",
    "            fold_importance[\"fold\"] = fold_n + 1\n",
    "            feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "\n",
    "    prediction /= n_fold\n",
    "    \n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}.'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    if model_type == 'lgb':\n",
    "        feature_importance[\"importance\"] /= n_fold\n",
    "        if plot_feature_importance:\n",
    "            cols = feature_importance[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(\n",
    "                by=\"importance\", ascending=False)[:50].index\n",
    "\n",
    "            best_features = feature_importance.loc[feature_importance.feature.isin(cols)]\n",
    "\n",
    "            plt.figure(figsize=(16, 12));\n",
    "            sns.barplot(x=\"importance\", y=\"feature\", data=best_features.sort_values(by=\"importance\", ascending=False));\n",
    "            plt.title('LGB Features (avg over folds)');\n",
    "        \n",
    "            return oof, prediction, feature_importance\n",
    "        return oof, prediction, scores\n",
    "    \n",
    "    else:\n",
    "        return oof, prediction, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boost': 'gbdt',\n",
    "          'feature_fraction': 0.05,\n",
    "          'learning_rate': 0.01,\n",
    "          'max_depth': -1,  \n",
    "          'metric':'auc',\n",
    "          'min_data_in_leaf': 50,\n",
    "          'num_leaves': 32,\n",
    "          'num_threads': -1,\n",
    "          'verbosity': 1,\n",
    "          'objective': 'binary'\n",
    "         }\n",
    "\n",
    "\n",
    "\n",
    "oof_lgb, prediction_lgb, scores = train_model(X_train, X_test, y_train, params=params, folds=folds, model_type='lgb', plot_feature_importance=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "sub['radiant_win_prob'] = prediction_lgb\n",
    "sub.to_csv('submission.csv', index=False)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
